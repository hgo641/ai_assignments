{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_Emotions_Classification_Sample_Code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hgo641/ai_assignments/blob/main/Face_Emotions_Classification_Sample_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9Q82b2OUQul"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN0td-zMxioA"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1SawJ5aN7IA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d140452-b839-4859-99d7-92033f59aa54"
      },
      "source": [
        "# connect your google drive to access data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_WxH0dmxkzP"
      },
      "source": [
        "fer2013_dataset_file_path = 'drive/My Drive/ai5/fer2013.csv'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWKlKWUmxkw-"
      },
      "source": [
        "train_images = []\n",
        "train_labels = []\n",
        "\n",
        "val_images = []\n",
        "val_labels = []\n",
        "\n",
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "with open(fer2013_dataset_file_path) as csv_file:\n",
        "  csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "  for row_id, row in enumerate(csv_reader):\n",
        "    if row_id == 0:\n",
        "      continue\n",
        "    label = np.zeros(7)\n",
        "    label[int(row[0])] = 1\n",
        "\n",
        "    image = list(map(int, row[1].split(' ')))\n",
        "    \n",
        "    if row[2] == 'Training':\n",
        "      train_labels.append(label)\n",
        "      train_images.append(image)\n",
        "    elif row[2] == 'PublicTest':\n",
        "      test_labels.append(label)\n",
        "      test_images.append(image)\n",
        "    elif row[2] == 'PrivateTest':\n",
        "      val_labels.append(label)\n",
        "      val_images.append(image)\n",
        "\n",
        "train_labels = np.asarray(train_labels, dtype=np.float32)\n",
        "train_images = np.asarray(train_images, dtype=np.float32).reshape(-1, 48, 48, 1)\n",
        "\n",
        "val_labels = np.asarray(val_labels, dtype=np.float32)\n",
        "val_images = np.asarray(val_images, dtype=np.float32).reshape(-1, 48, 48, 1)\n",
        "\n",
        "test_labels = np.asarray(test_labels, dtype=np.float32)\n",
        "test_images = np.asarray(test_images, dtype=np.float32).reshape(-1, 48, 48, 1)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hgImm0qMlLjK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PClDA3PExku0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07ee7f3e-517e-4a3b-8666-6a572136d6d3"
      },
      "source": [
        "print('Train images:', train_images.shape)\n",
        "print('Train labels:', train_labels.shape)\n",
        "\n",
        "print('Val images:', val_images.shape)\n",
        "print('Val labels:', val_labels.shape)\n",
        "\n",
        "print('Test images:', test_images.shape)\n",
        "print('Test labels:', test_labels.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images: (28709, 48, 48, 1)\n",
            "Train labels: (28709, 7)\n",
            "Val images: (3589, 48, 48, 1)\n",
            "Val labels: (3589, 7)\n",
            "Test images: (3589, 48, 48, 1)\n",
            "Test labels: (3589, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y01HTLVFxkri"
      },
      "source": [
        "# normalization\n",
        "train_images /= 255\n",
        "val_images /= 255\n",
        "test_images /= 255"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDVE1HN81u6E"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgZwcqlF1wGm"
      },
      "source": [
        "# Print Data Instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSVn4EiW1yCy"
      },
      "source": [
        "emotions = {\n",
        "    0: 'Angry', \n",
        "    1: 'Disgust',\n",
        "    2: 'Fear', \n",
        "    3: 'Happy',\n",
        "    4: 'Sad', \n",
        "    5: 'Surprise', \n",
        "    6: 'Neutral'\n",
        "}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAKK_t2_1yt5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "outputId": "0063fc31-e9af-44c9-cbe0-4fe26baddef1"
      },
      "source": [
        "index = 5\n",
        "print('Label array:', train_labels[index], '\\nLabel:', np.argmax(train_labels[index]),\n",
        "      '\\nEmotion:', emotions[np.argmax(train_labels[index])],\n",
        "      '\\nImage shape:', train_images[index].shape)\n",
        "plt.imshow(train_images[index].reshape(48, 48), cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label array: [0. 0. 1. 0. 0. 0. 0.] \n",
            "Label: 2 \n",
            "Emotion: Fear \n",
            "Image shape: (48, 48, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll1MEjIs1y3d"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjvULu3M3A-U"
      },
      "source": [
        "# Prepare Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocLFyI9W2_xN"
      },
      "source": [
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from keras.initializers import  RandomNormal\n",
        "input_shape = (48, 48, 1)\n",
        "num_labels = 7\n",
        "\n",
        "num_features = 64\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# layer 7개로 증가시킴\n",
        "# 커널 개수 128개로 증가시킴\n",
        "\n",
        "# 1st convolution layer\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding = 'same', input_shape=input_shape, bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding = 'same', input_shape=input_shape, bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# 3rd convolution layer\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "          \n",
        "# 5th convolution layer\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# 7th convolution layer\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "# Fully connected layers\n",
        "model.add(Dense(2048, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_labels, activation='softmax'))\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6BJbAyWe-NX",
        "outputId": "09500164-906b-4ed4-d53b-31d7917f9343"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_16 (Conv2D)          (None, 48, 48, 128)       1280      \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 48, 48, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 48, 48, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 23, 23, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 23, 23, 128)       0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 23, 23, 128)       147584    \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 23, 23, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 23, 23, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 11, 11, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 11, 11, 128)       0         \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 11, 11, 128)       147584    \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 11, 11, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 11, 11, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 5, 5, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 5, 5, 128)         0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 5, 5, 128)         147584    \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 5, 5, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 5, 5, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 2, 2, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2048)              1050624   \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 7)                 14343     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,101,383\n",
            "Trainable params: 2,100,359\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6hBP7VF2_u9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f7e3344-21d7-410c-8f15-e982ec228a3d"
      },
      "source": [
        "batch_size = 512\n",
        "# epochs 100으로 증가\n",
        "epochs = 100\n",
        "\n",
        "#Compliling the model with adam optimixer and categorical crossentropy loss\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#training the model\n",
        "train_history = model.fit(\n",
        "    train_images, train_labels, \n",
        "    batch_size=batch_size, \n",
        "    epochs=epochs, \n",
        "    validation_data=(val_images, val_labels), \n",
        "    verbose=1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "57/57 [==============================] - 30s 422ms/step - loss: 2.6082 - accuracy: 0.2017 - val_loss: 1.8567 - val_accuracy: 0.1889\n",
            "Epoch 2/100\n",
            "57/57 [==============================] - 22s 384ms/step - loss: 1.8381 - accuracy: 0.2345 - val_loss: 1.8494 - val_accuracy: 0.2285\n",
            "Epoch 3/100\n",
            "57/57 [==============================] - 21s 373ms/step - loss: 1.8133 - accuracy: 0.2438 - val_loss: 1.7935 - val_accuracy: 0.2566\n",
            "Epoch 4/100\n",
            "57/57 [==============================] - 21s 370ms/step - loss: 1.7934 - accuracy: 0.2520 - val_loss: 1.7750 - val_accuracy: 0.2669\n",
            "Epoch 5/100\n",
            "57/57 [==============================] - 21s 375ms/step - loss: 1.7885 - accuracy: 0.2515 - val_loss: 1.8136 - val_accuracy: 0.2722\n",
            "Epoch 6/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.7744 - accuracy: 0.2613 - val_loss: 1.8011 - val_accuracy: 0.2728\n",
            "Epoch 7/100\n",
            "57/57 [==============================] - 21s 375ms/step - loss: 1.7627 - accuracy: 0.2729 - val_loss: 1.8192 - val_accuracy: 0.2758\n",
            "Epoch 8/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.7536 - accuracy: 0.2758 - val_loss: 1.8670 - val_accuracy: 0.2753\n",
            "Epoch 9/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.7409 - accuracy: 0.2854 - val_loss: 1.7706 - val_accuracy: 0.3093\n",
            "Epoch 10/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.7256 - accuracy: 0.2967 - val_loss: 1.7384 - val_accuracy: 0.3238\n",
            "Epoch 11/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.6945 - accuracy: 0.3157 - val_loss: 1.8059 - val_accuracy: 0.3185\n",
            "Epoch 12/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.6703 - accuracy: 0.3323 - val_loss: 1.7075 - val_accuracy: 0.3385\n",
            "Epoch 13/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.6391 - accuracy: 0.3452 - val_loss: 1.7288 - val_accuracy: 0.3087\n",
            "Epoch 14/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.6174 - accuracy: 0.3569 - val_loss: 1.5637 - val_accuracy: 0.3867\n",
            "Epoch 15/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.5927 - accuracy: 0.3696 - val_loss: 1.6738 - val_accuracy: 0.3834\n",
            "Epoch 16/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.5719 - accuracy: 0.3810 - val_loss: 1.6048 - val_accuracy: 0.3711\n",
            "Epoch 17/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.5503 - accuracy: 0.3882 - val_loss: 1.5190 - val_accuracy: 0.4191\n",
            "Epoch 18/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.5329 - accuracy: 0.3976 - val_loss: 1.4909 - val_accuracy: 0.4185\n",
            "Epoch 19/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.5151 - accuracy: 0.4064 - val_loss: 1.5677 - val_accuracy: 0.4146\n",
            "Epoch 20/100\n",
            "57/57 [==============================] - 22s 383ms/step - loss: 1.4998 - accuracy: 0.4126 - val_loss: 1.6924 - val_accuracy: 0.4021\n",
            "Epoch 21/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.4897 - accuracy: 0.4175 - val_loss: 1.4486 - val_accuracy: 0.4436\n",
            "Epoch 22/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.4703 - accuracy: 0.4266 - val_loss: 1.4476 - val_accuracy: 0.4447\n",
            "Epoch 23/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.4553 - accuracy: 0.4266 - val_loss: 1.4658 - val_accuracy: 0.4472\n",
            "Epoch 24/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.4446 - accuracy: 0.4382 - val_loss: 1.4618 - val_accuracy: 0.4558\n",
            "Epoch 25/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.4252 - accuracy: 0.4447 - val_loss: 1.3962 - val_accuracy: 0.4709\n",
            "Epoch 26/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.4156 - accuracy: 0.4482 - val_loss: 1.4270 - val_accuracy: 0.4597\n",
            "Epoch 27/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.3975 - accuracy: 0.4569 - val_loss: 1.3657 - val_accuracy: 0.4787\n",
            "Epoch 28/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.3879 - accuracy: 0.4627 - val_loss: 1.3621 - val_accuracy: 0.4801\n",
            "Epoch 29/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.3798 - accuracy: 0.4657 - val_loss: 1.4724 - val_accuracy: 0.4528\n",
            "Epoch 30/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.3656 - accuracy: 0.4716 - val_loss: 1.4242 - val_accuracy: 0.4695\n",
            "Epoch 31/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.3585 - accuracy: 0.4765 - val_loss: 1.3475 - val_accuracy: 0.4926\n",
            "Epoch 32/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.3445 - accuracy: 0.4752 - val_loss: 1.3440 - val_accuracy: 0.4918\n",
            "Epoch 33/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.3445 - accuracy: 0.4793 - val_loss: 1.3320 - val_accuracy: 0.4982\n",
            "Epoch 34/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.3288 - accuracy: 0.4857 - val_loss: 1.3548 - val_accuracy: 0.4845\n",
            "Epoch 35/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.3204 - accuracy: 0.4904 - val_loss: 1.2974 - val_accuracy: 0.5038\n",
            "Epoch 36/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.3143 - accuracy: 0.4918 - val_loss: 1.3066 - val_accuracy: 0.5049\n",
            "Epoch 37/100\n",
            "57/57 [==============================] - 21s 375ms/step - loss: 1.3034 - accuracy: 0.4985 - val_loss: 1.3086 - val_accuracy: 0.5132\n",
            "Epoch 38/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.2934 - accuracy: 0.5006 - val_loss: 1.2970 - val_accuracy: 0.5149\n",
            "Epoch 39/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.2846 - accuracy: 0.5040 - val_loss: 1.2584 - val_accuracy: 0.5210\n",
            "Epoch 40/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.2783 - accuracy: 0.5089 - val_loss: 1.3168 - val_accuracy: 0.5085\n",
            "Epoch 41/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.2679 - accuracy: 0.5119 - val_loss: 1.2797 - val_accuracy: 0.5238\n",
            "Epoch 42/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.2557 - accuracy: 0.5174 - val_loss: 1.3181 - val_accuracy: 0.5054\n",
            "Epoch 43/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.2543 - accuracy: 0.5205 - val_loss: 1.2607 - val_accuracy: 0.5185\n",
            "Epoch 44/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.2516 - accuracy: 0.5179 - val_loss: 1.2551 - val_accuracy: 0.5210\n",
            "Epoch 45/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.2422 - accuracy: 0.5228 - val_loss: 1.2400 - val_accuracy: 0.5266\n",
            "Epoch 46/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.2353 - accuracy: 0.5273 - val_loss: 1.2675 - val_accuracy: 0.5174\n",
            "Epoch 47/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.2280 - accuracy: 0.5291 - val_loss: 1.2227 - val_accuracy: 0.5358\n",
            "Epoch 48/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.2239 - accuracy: 0.5320 - val_loss: 1.2649 - val_accuracy: 0.5196\n",
            "Epoch 49/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.2090 - accuracy: 0.5339 - val_loss: 1.2062 - val_accuracy: 0.5450\n",
            "Epoch 50/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.2035 - accuracy: 0.5397 - val_loss: 1.2140 - val_accuracy: 0.5352\n",
            "Epoch 51/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.1985 - accuracy: 0.5405 - val_loss: 1.2135 - val_accuracy: 0.5450\n",
            "Epoch 52/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.1931 - accuracy: 0.5418 - val_loss: 1.2189 - val_accuracy: 0.5461\n",
            "Epoch 53/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.1942 - accuracy: 0.5445 - val_loss: 1.2164 - val_accuracy: 0.5528\n",
            "Epoch 54/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.1788 - accuracy: 0.5495 - val_loss: 1.1819 - val_accuracy: 0.5628\n",
            "Epoch 55/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.1778 - accuracy: 0.5500 - val_loss: 1.2684 - val_accuracy: 0.5277\n",
            "Epoch 56/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.1703 - accuracy: 0.5544 - val_loss: 1.1988 - val_accuracy: 0.5564\n",
            "Epoch 57/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.1664 - accuracy: 0.5522 - val_loss: 1.1637 - val_accuracy: 0.5614\n",
            "Epoch 58/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.1595 - accuracy: 0.5567 - val_loss: 1.2315 - val_accuracy: 0.5469\n",
            "Epoch 59/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.1507 - accuracy: 0.5610 - val_loss: 1.1939 - val_accuracy: 0.5648\n",
            "Epoch 60/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.1491 - accuracy: 0.5627 - val_loss: 1.2419 - val_accuracy: 0.5358\n",
            "Epoch 61/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.1437 - accuracy: 0.5638 - val_loss: 1.1606 - val_accuracy: 0.5662\n",
            "Epoch 62/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.1374 - accuracy: 0.5643 - val_loss: 1.1577 - val_accuracy: 0.5729\n",
            "Epoch 63/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.1273 - accuracy: 0.5723 - val_loss: 1.1689 - val_accuracy: 0.5606\n",
            "Epoch 64/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.1270 - accuracy: 0.5705 - val_loss: 1.1646 - val_accuracy: 0.5681\n",
            "Epoch 65/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.1244 - accuracy: 0.5704 - val_loss: 1.1391 - val_accuracy: 0.5798\n",
            "Epoch 66/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.1143 - accuracy: 0.5754 - val_loss: 1.1452 - val_accuracy: 0.5726\n",
            "Epoch 67/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.1123 - accuracy: 0.5791 - val_loss: 1.1808 - val_accuracy: 0.5717\n",
            "Epoch 68/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.1024 - accuracy: 0.5793 - val_loss: 1.1466 - val_accuracy: 0.5779\n",
            "Epoch 69/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.1033 - accuracy: 0.5801 - val_loss: 1.1410 - val_accuracy: 0.5776\n",
            "Epoch 70/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.0971 - accuracy: 0.5824 - val_loss: 1.1266 - val_accuracy: 0.5879\n",
            "Epoch 71/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.0909 - accuracy: 0.5827 - val_loss: 1.1556 - val_accuracy: 0.5662\n",
            "Epoch 72/100\n",
            "57/57 [==============================] - 21s 375ms/step - loss: 1.0878 - accuracy: 0.5873 - val_loss: 1.1523 - val_accuracy: 0.5745\n",
            "Epoch 73/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.0820 - accuracy: 0.5847 - val_loss: 1.1043 - val_accuracy: 0.5885\n",
            "Epoch 74/100\n",
            "57/57 [==============================] - 22s 383ms/step - loss: 1.0775 - accuracy: 0.5913 - val_loss: 1.0935 - val_accuracy: 0.6043\n",
            "Epoch 75/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.0786 - accuracy: 0.5901 - val_loss: 1.1657 - val_accuracy: 0.5737\n",
            "Epoch 76/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.0662 - accuracy: 0.5939 - val_loss: 1.1586 - val_accuracy: 0.5743\n",
            "Epoch 77/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.0586 - accuracy: 0.5983 - val_loss: 1.1666 - val_accuracy: 0.5768\n",
            "Epoch 78/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.0628 - accuracy: 0.5972 - val_loss: 1.1213 - val_accuracy: 0.5926\n",
            "Epoch 79/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.0590 - accuracy: 0.5966 - val_loss: 1.0917 - val_accuracy: 0.5943\n",
            "Epoch 80/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.0482 - accuracy: 0.6037 - val_loss: 1.1252 - val_accuracy: 0.5798\n",
            "Epoch 81/100\n",
            "57/57 [==============================] - 21s 375ms/step - loss: 1.0424 - accuracy: 0.6051 - val_loss: 1.1293 - val_accuracy: 0.5795\n",
            "Epoch 82/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.0459 - accuracy: 0.6044 - val_loss: 1.1126 - val_accuracy: 0.5943\n",
            "Epoch 83/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.0425 - accuracy: 0.6035 - val_loss: 1.1167 - val_accuracy: 0.5876\n",
            "Epoch 84/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.0305 - accuracy: 0.6098 - val_loss: 1.1467 - val_accuracy: 0.5913\n",
            "Epoch 85/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.0341 - accuracy: 0.6096 - val_loss: 1.1137 - val_accuracy: 0.5971\n",
            "Epoch 86/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.0256 - accuracy: 0.6103 - val_loss: 1.1775 - val_accuracy: 0.5848\n",
            "Epoch 87/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.0232 - accuracy: 0.6118 - val_loss: 1.1396 - val_accuracy: 0.5907\n",
            "Epoch 88/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.0142 - accuracy: 0.6180 - val_loss: 1.1049 - val_accuracy: 0.5940\n",
            "Epoch 89/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.0178 - accuracy: 0.6159 - val_loss: 1.1404 - val_accuracy: 0.5876\n",
            "Epoch 90/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.0091 - accuracy: 0.6187 - val_loss: 1.1138 - val_accuracy: 0.5949\n",
            "Epoch 91/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 1.0057 - accuracy: 0.6186 - val_loss: 1.1004 - val_accuracy: 0.6018\n",
            "Epoch 92/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 0.9990 - accuracy: 0.6199 - val_loss: 1.1258 - val_accuracy: 0.5974\n",
            "Epoch 93/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 0.9960 - accuracy: 0.6226 - val_loss: 1.0998 - val_accuracy: 0.6002\n",
            "Epoch 94/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 0.9826 - accuracy: 0.6267 - val_loss: 1.1088 - val_accuracy: 0.6091\n",
            "Epoch 95/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 0.9958 - accuracy: 0.6233 - val_loss: 1.1184 - val_accuracy: 0.6010\n",
            "Epoch 96/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 0.9804 - accuracy: 0.6286 - val_loss: 1.2009 - val_accuracy: 0.5940\n",
            "Epoch 97/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 0.9859 - accuracy: 0.6256 - val_loss: 1.1066 - val_accuracy: 0.6069\n",
            "Epoch 98/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 0.9781 - accuracy: 0.6312 - val_loss: 1.1170 - val_accuracy: 0.6043\n",
            "Epoch 99/100\n",
            "57/57 [==============================] - 21s 376ms/step - loss: 0.9757 - accuracy: 0.6317 - val_loss: 1.1208 - val_accuracy: 0.6046\n",
            "Epoch 100/100\n",
            "57/57 [==============================] - 21s 375ms/step - loss: 0.9704 - accuracy: 0.6326 - val_loss: 1.0771 - val_accuracy: 0.6147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsxo1EzP2_tB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41ad719f-cd63-415c-e344-4d1afdeb4dde"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_images, test_labels, verbose=1)\n",
        "print('Loss:', loss, '\\nAccuracy:', accuracy * 100, '%')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - 1s 9ms/step - loss: 1.1304 - accuracy: 0.6021\n",
            "Loss: 1.130395531654358 \n",
            "Accuracy: 60.21175980567932 %\n"
          ]
        }
      ]
    }
  ]
}